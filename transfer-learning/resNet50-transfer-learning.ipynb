{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37664bitbase70e8918de8394c008ce5b5e752288847",
   "display_name": "Python 3.7.6 64-bit ('base')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models, transforms, datasets\n",
    "from torchsummary import summary\n",
    "from PIL import Image \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******************************\n",
    "# Define image transformations\n",
    "#******************************\n",
    "img_transforms = {\n",
    "    'train' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ]),\n",
    "    'valid' : transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ]),\n",
    "    'test'  : transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "    ])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 'bear', 1: 'chimp', 2: 'giraffe', 3: 'gorilla', 4: 'llama', 5: 'ostrich', 6: 'porcupine', 7: 'skunk', 8: 'triceratops', 9: 'zebra'}\n"
     ]
    }
   ],
   "source": [
    "#****************************************************\n",
    "# Define dataset directory paths and other variables\n",
    "#****************************************************\n",
    "#Paths to be used on Google colab\n",
    "# train_datadir = '/content/drive/MyDrive/Datasets/TransferLearning/train'\n",
    "# valid_datadir = '/content/drive/MyDrive/Datasets/TransferLearning/valid'\n",
    "# test_datadir = '/content/drive/MyDrive/Datasets/TransferLearning/test'\n",
    "\n",
    "#Paths to be used on local machine\n",
    "train_datadir = '../data/TransferLearning/train'\n",
    "valid_datadir = '../data/TransferLearning/valid'\n",
    "test_datadir = '../data/TransferLearning/test'\n",
    "\n",
    "data = {\n",
    "    'train' : datasets.ImageFolder(root=train_datadir,transform=img_transforms['train']),\n",
    "    'valid' : datasets.ImageFolder(root=valid_datadir,transform=img_transforms['valid']),\n",
    "    'test'  : datasets.ImageFolder(root=test_datadir,transform=img_transforms['test'])\n",
    "}\n",
    "\n",
    "train_datalen = len(data['train'])\n",
    "valid_datalen = len(data['valid'])\n",
    "test_datalen = len(data['test'])\n",
    "\n",
    "#Map the indices to the respective class names to see the output of the predictions\n",
    "idx_to_class = {index: classname for classname, index in data['train'].class_to_idx.items()}\n",
    "\n",
    "#Load the dataset in batches using the DataLoader\n",
    "batch_len = 32\n",
    "train_dataloader = torch.utils.data.DataLoader(data['train'], batch_size= batch_len, shuffle= True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(data['valid'], batch_size= batch_len, shuffle= True)\n",
    "test_dataloader  = torch.utils.data.DataLoader(data['test'], batch_size= batch_len, shuffle= True)\n",
    "\n",
    "print(idx_to_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the pre-trained model\n",
    "model_resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For transfer Learning we freeze the Feature extraction layer\n",
    "#Set requires_grad = False to freeze the parameters and \n",
    "#the gradients are not computed in the backward() \n",
    "for param in model_resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "#Customize the final fully connected layer to fit our dataset\n",
    "# fully_connected_input = model_resnet50.fc.in_features\n",
    "model_resnet50.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2048, 256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.4),\n",
    "    torch.nn.Linear(256, 10)\n",
    ")\n",
    "\n",
    "\n",
    "#Define the loss function and the optimizer\n",
    "loss_func = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model_resnet50.parameters())\n"
   ]
  },
  {
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function for training and validating the custom layers\n",
    "def train_and_validate(model, loss_function, optimizer, epochs=20):\n",
    "    training_start_time = time.time()\n",
    "    history = []\n",
    "    for epoch in epochs:\n",
    "        epoch_start_time = time.time()\n",
    "        print(\"Epoch {}/{}\".format(epoch+1,epochs))\n",
    "\n",
    "        #Initialize training and validation accuracy and loss for each epoch\n",
    "        train_acc = 0.00\n",
    "        train_loss = 0.00\n",
    "        valid_acc = 0.00\n",
    "        valid_loss = 0.00\n",
    "\n",
    "        for i, (inputs,labels) in enumerate(train_dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            #Always clear out gradients in every iteration \n",
    "            optimizer.zero_grad()\n",
    "            #Run a forward pass\n",
    "            outputs = model(inputs)\n",
    "            #Compute loss\n",
    "            loss = loss_function(outputs,labels)\n",
    "            #Compute gradients using Backpropogation\n",
    "            loss.backward()\n",
    "            #Update the parameters such as weights and biases\n",
    "            optimizer.step()\n",
    "\n",
    "            #Compute total loss for the batch and add to train_loss\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            #To compute accuracy we do predictions find out total correct outputs and calculate mean to obtain the percentage\n",
    "            _,predictions = torch.max(outputs.data, 1)\n",
    "            correct_predictions = predictions.eq(labels.data.view_as(predictions))\n",
    "            #Convert correct_predictions to float and calculate the mean\n",
    "            accuracy = torch.mean(correct_predictions.type(torch.FloatTensor))\n",
    "            train_acc += accuracy.item() * inputs.size(0)\n",
    "\n",
    "        #During validation, gradient tracking is not required\n",
    "        with torch.no_grad():  \n",
    "            model.eval()\n",
    "            for j, (inputs, labels) in valid_dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                #Perform a forward pass and run prediction on validation set\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                #Compute total validation loss\n",
    "                valid_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                #Compute validation accuracy\n",
    "                _, predictions = torch.max(output.data,1)\n",
    "                correct_predictions = predictions.eq(labels.data.view_as(predictions))\n",
    "                accuracy = torch.mean(correct_predictions.type(torch.FloatTensor))\n",
    "                valid_acc += accuracy.item() * inputs.size(0)\n",
    "        \n",
    "        avg_train_loss = train_loss/train_datalen\n",
    "        avg_train_acc = train_acc/train_datalen\n",
    "        avg_valid_loss = valid_loss/valid_datalen\n",
    "        avg_valid_acc = valid_acc/valid_datalen\n",
    "\n",
    "        history.append([avg_train_loss, avg_valid_loss, avg_train_acc, avg_valid_acc])\n",
    "\n",
    "        epoch_end_time = time.time()\n",
    "        print(\"Epoch: {:03f}, Training loss: {:.4f}, Training acc: {:.4f} %,\\n\\t\\tValid loss: {:.4f}, Valid acc: {:.4f} %, Time : {:.4f}s\".format(epoch, avg_train_loss, avg_train_acc*100, avg_valid_loss, avg_valid_acc, epoch_start_time - epoch_end_time))\n",
    "\n",
    "        torch.save(model,'resnet_model_'+str(epoch)+'.pt')\n",
    "\n",
    "    return model, history\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}