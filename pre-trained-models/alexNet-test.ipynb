{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'DenseNet',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'MNASNet',\n",
       " 'MobileNetV2',\n",
       " 'ResNet',\n",
       " 'ShuffleNetV2',\n",
       " 'SqueezeNet',\n",
       " 'VGG',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'quantization',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'utils',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "#The Pascal cased model names are the classes\n",
    "#The smaller case names of the corresponding classes are the convenience function that returns the instance of the model class\n",
    "# For example, densenet121, densenet161, densenet169, densenet201, all are instances of DenseNet class but with different number of layers â€“ 121,161,169 and 201, respectively  \n",
    "dir(models)"
   ]
  },
  {
   "source": [
    "# Download the pre-trained model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model\n",
    "alexnet = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n"
     ]
    }
   ],
   "source": [
    "print(alexnet)"
   ]
  },
  {
   "source": [
    "# Create a Transform to be applied on the inputs to the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406] , std=[0.229,0.224,0.225])\n",
    "])"
   ]
  },
  {
   "source": [
    "# Load and pre-process an Image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Image.open(\"..//data//images//lion.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      " Input shape :  torch.Size([3, 224, 224])\n batch shape :  torch.Size([1, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "input_img_transform = transform(input_img)\n",
    "print(\" Input shape : \", input_img_transform.shape)\n",
    "batch_transform = torch.unsqueeze(input_img_transform, 0) #Unsqueeze the image to send it out as a batch for predictions\n",
    "print(\" batch shape : \", batch_transform.shape)"
   ]
  },
  {
   "source": [
    "# Run Model Inference"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Set the model in eval mode\n",
    "alexnet.eval()\n",
    "output_vector = alexnet(batch_transform)\n",
    "output_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output _vector is a vector of 1000 classes\n",
    "#We need the class labels\n",
    "\n",
    "with open('..//data//docs//imagenet_classes.txt') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "labels = [k.split(', ')[1] for k in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lion\ntorch.Size([1])\ntensor([99.9972], grad_fn=<IndexBackward>)\n"
     ]
    }
   ],
   "source": [
    "#The output is a row vector so we find the max in dim : 1 (column) \n",
    "_, index = torch.max(output_vector,1) \n",
    "print(labels[index])\n",
    "print(index.shape)\n",
    "\n",
    "# Obtain the probabilities using the softmax function along dim : 1 i.e column %\n",
    "percent = torch.nn.functional.softmax(output_vector,dim=1)[0] * 100\n",
    "print(percent[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('lion', 99.99720001220703),\n",
       " ('Persian_cat', 0.0006670920993201435),\n",
       " ('Pekinese', 0.0005496992380358279),\n",
       " ('Shetland_sheepdog', 0.0005062207928858697),\n",
       " ('ram', 0.0004189471947029233),\n",
       " ('ox', 8.515155059285462e-05)]"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "# Sort the indices in decending order of probabilities\n",
    "_, indices = torch.sort(output_vector,1,True)\n",
    "print(indices.shape)\n",
    "\n",
    "# Print the top 6 probabilities\n",
    "[(labels[idx], percent[idx].item()) for idx in indices[0,:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Code-snippets for Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 3])\ntensor([[[1, 2, 3]],\n\n        [[4, 5, 6]],\n\n        [[7, 8, 9]]])\ntorch.Size([3, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "a  =  torch.tensor([[1,2,3],\n",
    "                    [4,5,6],\n",
    "                    [7,8,9]])\n",
    "b = torch.unsqueeze(a,1)\n",
    "print(a.shape)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6]])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 71
    }
   ],
   "source": [
    "c = torch.tensor([[1,2,3,4,5,6]])\n",
    "print(c)\n",
    "_,d = torch.max(c,0)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}